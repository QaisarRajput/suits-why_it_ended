{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "# tokenizer = word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"orignal dump\"\n",
    "df = pd.read_csv(\"Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Season</th>\n",
       "      <th>SeasonID</th>\n",
       "      <th>Episode</th>\n",
       "      <th>EpisodeID</th>\n",
       "      <th>DialogueLines</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Char_count</th>\n",
       "      <th>Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suits.S01E01.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E01</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Gerald Tate's here.\", \"He wants to know what...</td>\n",
       "      <td>Gerald Tate's here. He wants to know what's ha...</td>\n",
       "      <td>9371</td>\n",
       "      <td>48607</td>\n",
       "      <td>3501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suits.S01E02.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E02</td>\n",
       "      <td>2</td>\n",
       "      <td>['What is that, three in a row?', 'That would ...</td>\n",
       "      <td>What is that, three in a row? That would be fo...</td>\n",
       "      <td>6026</td>\n",
       "      <td>30980</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suits.S01E03.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E03</td>\n",
       "      <td>3</td>\n",
       "      <td>[\"♪ It's a perfect day ♪\", '♪ To go and tie on...</td>\n",
       "      <td>♪ It's a perfect day ♪ ♪ To go and tie one on ...</td>\n",
       "      <td>5843</td>\n",
       "      <td>30808</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suits.S01E04.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E04</td>\n",
       "      <td>4</td>\n",
       "      <td>['Harvard trivia, the lightning round.', '[Sna...</td>\n",
       "      <td>Harvard trivia, the lightning round. [Snaps] G...</td>\n",
       "      <td>6469</td>\n",
       "      <td>34831</td>\n",
       "      <td>2307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suits.S01E05.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E05</td>\n",
       "      <td>5</td>\n",
       "      <td>['Ross.', 'Triple double, courtesy of', \"Ameri...</td>\n",
       "      <td>Ross. Triple double, courtesy of America's fav...</td>\n",
       "      <td>5961</td>\n",
       "      <td>31022</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File Season  SeasonID Episode  EpisodeID  \\\n",
       "0  Suits.S01E01.srt    S01         1     E01          1   \n",
       "1  Suits.S01E02.srt    S01         1     E02          2   \n",
       "2  Suits.S01E03.srt    S01         1     E03          3   \n",
       "3  Suits.S01E04.srt    S01         1     E04          4   \n",
       "4  Suits.S01E05.srt    S01         1     E05          5   \n",
       "\n",
       "                                       DialogueLines  \\\n",
       "0  [\"Gerald Tate's here.\", \"He wants to know what...   \n",
       "1  ['What is that, three in a row?', 'That would ...   \n",
       "2  [\"♪ It's a perfect day ♪\", '♪ To go and tie on...   \n",
       "3  ['Harvard trivia, the lightning round.', '[Sna...   \n",
       "4  ['Ross.', 'Triple double, courtesy of', \"Ameri...   \n",
       "\n",
       "                                                Text  Word_count  Char_count  \\\n",
       "0  Gerald Tate's here. He wants to know what's ha...        9371       48607   \n",
       "1  What is that, three in a row? That would be fo...        6026       30980   \n",
       "2  ♪ It's a perfect day ♪ ♪ To go and tie one on ...        5843       30808   \n",
       "3  Harvard trivia, the lightning round. [Snaps] G...        6469       34831   \n",
       "4  Ross. Triple double, courtesy of America's fav...        5961       31022   \n",
       "\n",
       "   Stopwords  \n",
       "0       3501  \n",
       "1       2222  \n",
       "2       2150  \n",
       "3       2307  \n",
       "4       2069  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = []\n",
    "for t in df[\"DialogueLines\"]:\n",
    "    ti = literal_eval(str(t).lower())\n",
    "    tokenized.extend(ti)\n",
    "tokenized = [tokenizer(t.replace(\"'\",\"\")) for t in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gerald', 'tates', 'here'],\n",
       " ['he', 'wants', 'to', 'know', 'whats', 'happening', 'to', 'his', 'deal'],\n",
       " ['go', 'get', 'harvey'],\n",
       " ['i', 'check'],\n",
       " ['raise'],\n",
       " ['im', 'all', 'in'],\n",
       " ['you', 'can', 'pay', 'me', 'later'],\n",
       " ['i', 'got', 'to', 'go'],\n",
       " ['gentlemen'],\n",
       " ['im', 'paying', 'you', 'millions', 'and', 'youre', 'telling', 'me']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create the bigrams\n",
    "bigram_model = Phrases(tokenized, delimiter=b\" \")\n",
    "bigram_sentences = []\n",
    "bigram_sentences_t = []\n",
    "#apply the trained model to a sentence\n",
    "for t_sentence in tokenized:\n",
    "    bigram_sentences.append(u' '.join(bigram_model[t_sentence]))\n",
    "    bigram_sentences_t.append(bigram_model[t_sentence])\n",
    "#get a trigram model out of the bigram\n",
    "trigram_model = Phrases(bigram_sentences_t, delimiter=b\" \")\n",
    "\n",
    "trigram_sentences = []\n",
    "trigram_sentences_t = []\n",
    "#apply the trained model to a sentence\n",
    "for t_sentence in bigram_sentences_t:\n",
    "    trigram_sentences.append(u' '.join(trigram_model[t_sentence]))\n",
    "    trigram_sentences_t.append(trigram_model[t_sentence])\n",
    "#get a trigram model out of the bigram\n",
    "fourgram_model = Phrases(trigram_sentences_t, delimiter=b\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    words = tokenizer(text)\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"Text_lower\"] = df[\"Text\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"BiGramPhraser\"] = df[\"Text\"].apply(lambda x : bigram_model[tokenizer(x)]) \n",
    "# df[\"TriGramPhraser\"] = df[\"Text\"].apply(lambda x : trigram_model[tokenizer(x)]) \n",
    "# df[\"FourGramPhraser\"] = df[\"Text\"].apply(lambda x : fourgram_model[tokenizer(x)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = []\n",
    "scores = []\n",
    "for phrase, score in bigram_model.export_phrases(tokenized):\n",
    "    phrases.append(phrase)\n",
    "    scores.append(score)\n",
    "\n",
    "for phrase, score in trigram_model.export_phrases(bigram_sentences_t):\n",
    "    phrases.append(phrase)\n",
    "    scores.append(score)\n",
    "\n",
    "for phrase, score in fourgram_model.export_phrases(trigram_sentences_t):\n",
    "    phrases.append(phrase)\n",
    "    scores.append(score)\n",
    "\n",
    "df_phrases = pd.DataFrame({\"Phrase\":phrases, \"Score\": scores, \"Words\": [len(p.split(b\" \")) for p in phrases]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrases.sort_values(by=['Score'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrases = df_phrases.drop_duplicates()#head(20)\n",
    "df_phrases = df_phrases.dropna()#head(20)\n",
    "# df_phrases[df_phrases.isnull().any(axis=1)]\n",
    "# df_phrases[\"Phrase\"] = df_phrases[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phrase     object\n",
       "Score     float64\n",
       "Words       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk_keyword_list = [b'web',\n",
    "                    b'resync',\n",
    "                    b'addic7ed',\n",
    "                    b'font',\n",
    "                    b'indistinct',\n",
    "                    b'fffff',\n",
    "                    b'tvsubtitles',\n",
    "                    b'knock at door',\n",
    "                    b'soft rock music',\n",
    "                    b'air date',\n",
    "                    b'color',\n",
    "                    b'sync corrected',\n",
    "                     b'00f'\n",
    "                    ]\n",
    "df_phrases.dtypes\n",
    "# '|'.join(junk_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrases = df_phrases[~df_phrases['Phrase'].str.contains(b'|'.join(junk_keyword_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Score</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>b'wakefield cady'</td>\n",
       "      <td>8318.172840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>b'cum laude'</td>\n",
       "      <td>7895.765625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45508</th>\n",
       "      <td>b'shame shame shame shame'</td>\n",
       "      <td>7290.897959</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38939</th>\n",
       "      <td>b'blah blah blah'</td>\n",
       "      <td>7217.252525</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44626</th>\n",
       "      <td>b'quid pro quo'</td>\n",
       "      <td>6379.535714</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27937</th>\n",
       "      <td>b'van dyke'</td>\n",
       "      <td>5614.766667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28352</th>\n",
       "      <td>b'hudson mills'</td>\n",
       "      <td>5614.766667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13879</th>\n",
       "      <td>b'whistle blower'</td>\n",
       "      <td>5614.766667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45226</th>\n",
       "      <td>b'having panic attacks'</td>\n",
       "      <td>5582.093750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38640</th>\n",
       "      <td>b'elevator bell dings'</td>\n",
       "      <td>5438.963141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Phrase        Score  Words\n",
       "1936            b'wakefield cady'  8318.172840      2\n",
       "12781                b'cum laude'  7895.765625      2\n",
       "45508  b'shame shame shame shame'  7290.897959      4\n",
       "38939           b'blah blah blah'  7217.252525      3\n",
       "44626             b'quid pro quo'  6379.535714      3\n",
       "27937                 b'van dyke'  5614.766667      2\n",
       "28352             b'hudson mills'  5614.766667      2\n",
       "13879           b'whistle blower'  5614.766667      2\n",
       "45226     b'having panic attacks'  5582.093750      3\n",
       "38640      b'elevator bell dings'  5438.963141      3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrases.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words with Length :2\n",
      "\n",
      "[b'wakefield cady', b'cum laude', b'van dyke', b'hudson mills', b'whistle blower', b'prune juice', b'silver platter', b'wrongful termination', b'footsteps approaching', b'reform corp', b'heartbeat thumping', b'stable shelters', b'starboard airlines', b'albert chung', b'clerical error', b'liberty rail', b'trent devon', b'panic attacks', b'rick sorkin', b'fletcher engines', b'stalking horse', b'effective immediately', b'olive branch', b'phillip allen', b'sloane moseley', b'holly cromwell', b'blah blah', b'sexual harassment', b'allison holt', b'vice president', b'sarah layton', b'lena lunders', b'waiter gillie', b'maria gomez', b'dana scott', b'clears throat', b'clifford danner', b'jesus christ', b'emerson petroleum', b'bike messenger', b'exhales sharply', b'paul porter', b'non compete', b'malicious prosecution', b'star trek', b'sam tull', b'sole purpose', b'shame shame', b'folsom foods', b'neil stillman', b'gavin andrews', b'monica eton', b'lola jensen', b'co conspirator', b'pro bono', b'coastal motors', b'insider trading', b'distribution centers', b'simon lowe', b'14 www', b'innocence project', b'photographic memory', b'tortious interference', b'david fox', b'franklin courier', b'gender discrimination', b'r o', b'teddy doyle', b'due diligence', b'jim reynolds', b'peter minto', b'hedge fund', b'mckernon motors', b'colonel mariga', b'press release', b'rand kaldor', b'dominic barone', b'eliot stemple', b'dr agard', b'henry gerard', b'gavel bangs', b'bratton gould', b'opposing counsel', b'e c', b't r', b'stephen huntley', b'stu buzzini', b'leonard bailey', b'heat sensors', b'greenback boogie', b'tony gianopolous', b'united states', b'elevator bell', b'joan walsh', b'velocity data', b'ha ha', b'joe henderson', b'bran bars', b'bearing gifts', b'o j']\n",
      "\n",
      "\n",
      "Top Words with Length :3\n",
      "\n",
      "[b'blah blah blah', b'quid pro quo', b'having panic attacks', b'elevator bell dings', b'd o j', b't r o', b'at 8 00', b'an investment banker', b'velocity data solutions', b's e c', b'previously on suits', b'gods green earth', b'whoa whoa whoa', b'sooner or later', b'1 2 million', b'next two weeks', b'pearson specter litt', b'attorney client privilege', b'money wanna stay', b'16 year old', b'rand kaldor zane', b'an alibi witness', b'your mouth shut', b'12 years ago', b'next two years', b'danbury federal prison', b'rachel elizabeth zane', b'busy making money', b'social security number', b'how many times', b'u s attorney', b'ive never seen', b'seeing each other', b'ive ever seen', b'harvard law school', b'more important than', b'an hour ago', b'11 years old', b'ill even eat', b'piece of paper', b'youngest senior partner', b'ive ever met', b'new york bar', b'two days ago', b'sure as hell', b'six months ago', b'lot more than', b'five years ago', b'couple of days', b'half an hour', b'oh my god', b'as far as', b'as long as', b'all step back', b'known each other', b'wait till tomorrow', b'whole damn thing', b'appreciate your concern', b'long time ago', b'make any sense', b'seven years ago', b'as soon as', b'an innocent man', b'stay away from', b'last five years', b'as much as', b'piece of shit', b'robert zanes daughter', b'speaking of which', b'exact same thing', b'harvard file room', b'objection your honor', b'15 years ago', b'go right ahead', b'too much trouble', b'three years ago', b'attorney generals office', b'few weeks ago', b'theres no way', b'among other things', b'two hours ago', b'must have been', b'two years ago', b'keep an eye', b'doesnt make sense', b'might as well', b'their buy ins', b'everybody wanna see', b'two days later', b'had an affair', b'some bad news', b'ive ever heard', b'ive never known', b'every single day', b'four years ago', b'an old man', b'get another piece', b'wait wait wait', b'ive never heard', b'whats gonna happen']\n",
      "\n",
      "\n",
      "Top Words with Length :4\n",
      "\n",
      "[b'shame shame shame shame', b'missus so busy busy', b'good cop bad cop', b'busy busy making money', b'u s attorneys office', b'on such short notice', b'missy is so busy', b'so busy busy making', b'heres whats gonna happen', b'son of a bitch', b'keep your mouth shut', b'at pearson specter litt', b'as soon as possible', b'whoa whoa whoa whoa', b'wait wait wait wait', b'beehive of your mind', b'crime he didnt commit', b'doesnt make any sense', b'all that time imagine', b'everybody wanna know how', b'now if youll excuse', b'no matter how much', b'ive been waiting for', b'ill take care of', b'set this whole thing', b'thats never gonna happen', b'little busy right now', b'this whole thing started', b'ive been thinking about', b'us on such short', b'weve been over this', b'with all due respect', b'see thats funny because', b'theres nothing wrong with', b'im not interested in', b'keep an eye on', b'if youll excuse me', b'know if youve noticed', b'im not going anywhere', b'ill even eat a']\n",
      "\n",
      "\n",
      "Top Words with Length :5\n",
      "\n",
      "[b'wanna stay for your meal', b'as far as im concerned', b'get another piece of pie', b'very busy busy making money', b'so busy busy making money']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopScoreN = 100\n",
    "for i in range(2, 6):\n",
    "    Words = df_phrases.loc[df_phrases[\"Words\"] == i , [\"Phrase\"]][:TopScoreN]\n",
    "    Words = [w[0] for w in Words.values]\n",
    "    print(\"Top Words with Length :%s\\n\"%(str(i)))\n",
    "    print(Words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_frequencies(phrase):\n",
    "    try:\n",
    "        phrase_regex = re.compile(phrase.decode(\"utf-8\"))\n",
    "        count = 0\n",
    "        for episode in df[\"Text_lower\"].values:\n",
    "            c = 0\n",
    "            c = len(re.findall(phrase_regex, episode))\n",
    "            count = count + c\n",
    "        return count\n",
    "    except Exception as e:\n",
    "#         print(phrase)\n",
    "        raise\n",
    "\n",
    "df_phrases[\"Freq\"] = df_phrases[\"Phrase\"].apply(lambda x: get_phrase_frequencies(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrases.sort_values(by=['Freq', 'Score'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words with Length :2\n",
      "\n",
      "[(b'talking about', 862), (b'right now', 773), (b'all right', 619), (b'of course', 345), (b'doing here', 342), (b'kind of', 338), (b'mike ross', 330), (b'talk about', 328), (b'your honor', 321), (b'first place', 314), (b'piece of', 285), (b'which means', 282), (b'excuse me', 261), (b'everybody wanna', 250), (b'look at', 248), (b'find out', 246), (b'care about', 242), (b'figure out', 233), (b'instead of', 231), (b'harvey specter', 230), (b'more than', 229), (b'my god', 229), (b'last night', 214), (b'son of', 201), (b'found out', 200), (b's office', 192), (b'he wants', 191), (b'your ass', 183), (b'managing partner', 181), (b'make sure', 178), (b'looking for', 176), (b'each other', 175), (b'my life', 172), (b'our own', 167), (b'how much', 167), (b'last time', 165), (b'senior partner', 161), (b'your wife', 160), (b'years ago', 159), (b'rest of', 158), (b'lot of', 158), (b'be able', 153), (b'same thing', 152), (b'take care', 149), (b'dramatic music', 148), (b'god damn', 148), (b'gonna happen', 148), (b'your own', 147), (b'whole thing', 146), (b'law school', 144), (b'name partner', 142), (b'thinking about', 141), (b'long as', 140), (b'my own', 140), (b'as long', 137), (b'wanna see', 132), (b'making money', 131), (b'mr specter', 130), (b'better than', 130), (b'front of', 130), (b'working on', 130), (b'greenback boogie', 129), (b'louis litt', 129), (b'in front', 129), (b'wanna stay', 128), (b'another piece', 127), (b'your meal', 127), (b'of pie', 127), (b'robert zane', 125), (b'turns out', 125), (b'busy making', 123), (b'pearson specter', 122), (b'someone else', 122), (b'someone who', 122), (b'no idea', 120), (b'part of', 118), (b'so much', 113), (b'middle of', 113), (b'so busy', 113), (b'our clients', 111), (b'sure as', 111), (b'he knows', 111), (b'looks like', 109), (b'as much', 109), (b'five years', 107), (b'new york', 104), (b'go ahead', 103), (b'end of', 103), (b'at least', 102), (b'only way', 102)]\n",
      "\n",
      "\n",
      "Top Words with Length :3\n",
      "\n",
      "[(b'son of a', 198), (b'oh my god', 193), (b'a lot of', 152), (b'take care of', 144), (b'as long as', 135), (b'for your wife', 129), (b'in front of', 128), (b'get another piece', 126), (b'for your meal', 126), (b'another piece of', 126), (b'everybody wanna see', 125), (b'wanna stay for', 125), (b'everybody wanna know', 125), (b'busy making money', 123), (b'this whole thing', 108), (b'as far as', 95), (b'sure as hell', 93), (b'have no idea', 90), (b'might as well', 89), (b'all step back', 84), (b'as much as', 83), (b'money wanna stay', 80), (b'piece of sh', 73), (b'piece of shit', 63), (b'as soon as', 53), (b'not gonna happen', 53), (b'figure out how', 52), (b'pearson specter litt', 51), (b's e c', 49), (b'previously on suits', 49), (b'on top of', 46), (b'beehive of your', 43), (b'get rid of', 41), (b'not interested in', 35), (b'that time imagine', 35), (b'at pearson specter', 34), (b'u s attorney', 33), (b'took care of', 33), (b'on my desk', 33), (b'we talked about', 32), (b'what difference does', 32), (b'in exchange for', 30), (b'some kind of', 30), (b'an hour ago', 28), (b'whether or not', 28), (b'not going anywhere', 27), (b'kind of man', 27), (b'as managing partner', 26), (b'12 years ago', 25), (b'elevator bell dings', 24), (b'five years ago', 24), (b'taken care of', 24), (b'never gonna happen', 24), (b'on behalf of', 23), (b'in other words', 22), (b'wanna talk about', 21), (b'my whole life', 21), (b'how many times', 20), (b'lot more than', 20), (b'am so sorry', 20), (b'taking care of', 20), (b'more important than', 19), (b'at pearson hardman', 19), (b'gonna end up', 19), (b'an innocent man', 18), (b'last five years', 18), (b'kind of person', 18), (b'had no idea', 18), (b'kind of lawyer', 18), (b'whoa whoa whoa', 17), (b'two days ago', 17), (b'stay away from', 17), (b'speaking of which', 17), (b'exact same thing', 17), (b'must have been', 17), (b'none of them', 17), (b'some sort of', 17), (b'middle of something', 17), (b't r o', 16), (b'new york bar', 16), (b'make any sense', 16), (b'objection your honor', 16), (b'sure as shit', 16), (b'being accused of', 16), (b'long time ago', 15), (b'go right ahead', 15), (b'had an affair', 15), (b'say good bye', 15), (b'coming after us', 15), (b'hell away from', 15), (b'lot of money', 15), (b'attorney client privilege', 14), (b'seeing each other', 14), (b'six months ago', 14), (b'wait wait wait', 14), (b'so much as', 14), (b'in open court', 14), (b'no intention of', 14), (b'next two years', 13), (b'piece of paper', 13)]\n",
      "\n",
      "\n",
      "Top Words with Length :4\n",
      "\n",
      "[(b'son of a bitch', 194), (b'busy busy making money', 98), (b'so busy busy making', 84), (b'everybody wanna know how', 80), (b'missy is so busy', 52), (b'beehive of your mind', 43), (b'missus so busy busy', 36), (b'all that time imagine', 35), (b'at pearson specter litt', 16), (b'good cop bad cop', 10), (b'with all due respect', 10), (b'on such short notice', 9), (b'as soon as possible', 8), (b'no matter how much', 8), (b'keep an eye on', 8), (b'shame shame shame shame', 7), (b'keep your mouth shut', 7), (b'whoa whoa whoa whoa', 7), (b'set this whole thing', 7), (b'this whole thing started', 7), (b'little busy right now', 6), (b'us on such short', 6), (b'wait wait wait wait', 5), (b'ill take care of', 5), (b'u s attorneys office', 2), (b'heres whats gonna happen', 0), (b'crime he didnt commit', 0), (b'doesnt make any sense', 0), (b'now if youll excuse', 0), (b'ive been waiting for', 0), (b'thats never gonna happen', 0), (b'ive been thinking about', 0), (b'weve been over this', 0), (b'see thats funny because', 0), (b'theres nothing wrong with', 0), (b'im not interested in', 0), (b'if youll excuse me', 0), (b'know if youve noticed', 0), (b'im not going anywhere', 0), (b'ill even eat a', 0)]\n",
      "\n",
      "\n",
      "Top Words with Length :5\n",
      "\n",
      "[(b'wanna stay for your meal', 125), (b'get another piece of pie', 125), (b'so busy busy making money', 84), (b'very busy busy making money', 7), (b'as far as im concerned', 0)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopScoreN = 100\n",
    "for i in range(2, 6):\n",
    "    Words = df_phrases.loc[df_phrases[\"Words\"] == i , [\"Phrase\",\"Freq\"]][:TopScoreN]\n",
    "    Words = [(w[0], w[1]) for w in Words.values if len(w[0]) > 4]\n",
    "    print(\"Top Words with Length :%s\\n\"%(str(i)))\n",
    "    print(Words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Season</th>\n",
       "      <th>SeasonID</th>\n",
       "      <th>Episode</th>\n",
       "      <th>EpisodeID</th>\n",
       "      <th>DialogueLines</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Char_count</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suits.S01E01.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E01</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Gerald Tate's here.\", \"He wants to know what...</td>\n",
       "      <td>Gerald Tate's here. He wants to know what's ha...</td>\n",
       "      <td>9371</td>\n",
       "      <td>48607</td>\n",
       "      <td>3501</td>\n",
       "      <td>gerald tate s here he wants to know what s hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suits.S01E02.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E02</td>\n",
       "      <td>2</td>\n",
       "      <td>['What is that, three in a row?', 'That would ...</td>\n",
       "      <td>What is that, three in a row? That would be fo...</td>\n",
       "      <td>6026</td>\n",
       "      <td>30980</td>\n",
       "      <td>2222</td>\n",
       "      <td>what is that three in a row that would be four...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suits.S01E03.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E03</td>\n",
       "      <td>3</td>\n",
       "      <td>[\"♪ It's a perfect day ♪\", '♪ To go and tie on...</td>\n",
       "      <td>♪ It's a perfect day ♪ ♪ To go and tie one on ...</td>\n",
       "      <td>5843</td>\n",
       "      <td>30808</td>\n",
       "      <td>2150</td>\n",
       "      <td>it s a perfect day to go and tie one on the 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suits.S01E04.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E04</td>\n",
       "      <td>4</td>\n",
       "      <td>['Harvard trivia, the lightning round.', '[Sna...</td>\n",
       "      <td>Harvard trivia, the lightning round. [Snaps] G...</td>\n",
       "      <td>6469</td>\n",
       "      <td>34831</td>\n",
       "      <td>2307</td>\n",
       "      <td>harvard trivia the lightning round snaps go pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suits.S01E05.srt</td>\n",
       "      <td>S01</td>\n",
       "      <td>1</td>\n",
       "      <td>E05</td>\n",
       "      <td>5</td>\n",
       "      <td>['Ross.', 'Triple double, courtesy of', \"Ameri...</td>\n",
       "      <td>Ross. Triple double, courtesy of America's fav...</td>\n",
       "      <td>5961</td>\n",
       "      <td>31022</td>\n",
       "      <td>2069</td>\n",
       "      <td>ross triple double courtesy of america s favor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File Season  SeasonID Episode  EpisodeID  \\\n",
       "0  Suits.S01E01.srt    S01         1     E01          1   \n",
       "1  Suits.S01E02.srt    S01         1     E02          2   \n",
       "2  Suits.S01E03.srt    S01         1     E03          3   \n",
       "3  Suits.S01E04.srt    S01         1     E04          4   \n",
       "4  Suits.S01E05.srt    S01         1     E05          5   \n",
       "\n",
       "                                       DialogueLines  \\\n",
       "0  [\"Gerald Tate's here.\", \"He wants to know what...   \n",
       "1  ['What is that, three in a row?', 'That would ...   \n",
       "2  [\"♪ It's a perfect day ♪\", '♪ To go and tie on...   \n",
       "3  ['Harvard trivia, the lightning round.', '[Sna...   \n",
       "4  ['Ross.', 'Triple double, courtesy of', \"Ameri...   \n",
       "\n",
       "                                                Text  Word_count  Char_count  \\\n",
       "0  Gerald Tate's here. He wants to know what's ha...        9371       48607   \n",
       "1  What is that, three in a row? That would be fo...        6026       30980   \n",
       "2  ♪ It's a perfect day ♪ ♪ To go and tie one on ...        5843       30808   \n",
       "3  Harvard trivia, the lightning round. [Snaps] G...        6469       34831   \n",
       "4  Ross. Triple double, courtesy of America's fav...        5961       31022   \n",
       "\n",
       "   Stopwords                                         Text_lower  \n",
       "0       3501  gerald tate s here he wants to know what s hap...  \n",
       "1       2222  what is that three in a row that would be four...  \n",
       "2       2150  it s a perfect day to go and tie one on the 20...  \n",
       "3       2307  harvard trivia the lightning round snaps go pu...  \n",
       "4       2069  ross triple double courtesy of america s favor...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
